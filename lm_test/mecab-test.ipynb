{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-27T03:00:37.807810910Z",
     "start_time": "2023-10-27T03:00:37.757646124Z"
    }
   },
   "outputs": [],
   "source": [
    "import mecab_ko as Mecab\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.4\n",
      "0.25\n",
      "2.2250738585072626e-308\n",
      "6.206021746903507e-78\n"
     ]
    }
   ],
   "source": [
    "text = \"아버지가방에들어가신다\"\n",
    "tagger = Mecab.Tagger(\"-Owakati\")\n",
    "a = tagger.parse(\"아버지 가방에 들어가신다\").split()\n",
    "b = tagger.parse(\"아버지가 방에 들어가신다\").split()\n",
    "print(sentence_bleu([a], b, weights=(1,0,0,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,1,0,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,0,1,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,0,0,1)))\n",
    "print(sentence_bleu([a], b, weights=(0.25,0.25,0.25,0.25)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T03:00:38.012362786Z",
     "start_time": "2023-10-27T03:00:37.964693799Z"
    }
   },
   "id": "53a008c5d533c233"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2',\n",
    "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "    pad_token='<pad>', mask_token='<mask>')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T03:00:40.229666149Z",
     "start_time": "2023-10-27T03:00:38.087269999Z"
    }
   },
   "id": "e22265f03e6dff0d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49123845184678916\n",
      "0.40936537653899097\n",
      "0.272910251025994\n",
      "1.8217363958297824e-308\n",
      "5.623118184955381e-78\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer.tokenize('아버지 가방에 들어가신다')\n",
    "b = tokenizer.tokenize('아버지가 방에 들어가신다')\n",
    "print(sentence_bleu([a], b, weights=(1,0,0,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,1,0,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,0,1,0)))\n",
    "print(sentence_bleu([a], b, weights=(0,0,0,1)))\n",
    "print(sentence_bleu([a], b, weights=(0.25,0.25,0.25,0.25)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T03:00:40.236940126Z",
     "start_time": "2023-10-27T03:00:40.231386300Z"
    }
   },
   "id": "68c0dfc749715054"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "879811c6f256a474"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
